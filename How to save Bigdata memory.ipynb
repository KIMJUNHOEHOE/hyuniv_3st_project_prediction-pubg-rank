{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Deleting unused variables and gc.collect()\n",
    "\n",
    "Unlike other languages, Python does not efficiently utilize memory. Variables that we do not use, or that we use or discard, also occupy memory. So we have to keep in mind two things.\n",
    "\n",
    "1. Unused variables are deleted using del.\n",
    "\n",
    "2. After del deleting it, it is surely removed from memory through the command gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./data/train_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_sample = data_df.copy()\n",
    "del data_df_sample\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Presetting the datatypes\n",
    "\n",
    "Python automatically reads the data type, which causes a lot of memory waste. So if we know in advance the memory we will set up, we can use it much more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'Id'                : 'uint32',\n",
    "        'groupId'           : 'uint32',\n",
    "        'matchId'           : 'uint16',\n",
    "        'assists'           : 'uint8',\n",
    "        'boosts'            : 'uint8',\n",
    "        'damageDealt'       : 'float16',\n",
    "        'DBNOs'             : 'uint8',\n",
    "        'headshotKills'     : 'uint8', \n",
    "        'heals'             : 'uint8',    \n",
    "        'killPlace'         : 'uint8',    \n",
    "        'killPoints'        : 'uint8',    \n",
    "        'kills'             : 'uint8',    \n",
    "        'killStreaks'       : 'uint8',    \n",
    "        'longestKill'       : 'float16',    \n",
    "        'maxPlace'          : 'uint8',    \n",
    "        'numGroups'         : 'uint8',    \n",
    "        'revives'           : 'uint8',    \n",
    "        'rideDistance'      : 'float16',    \n",
    "        'roadKills'         : 'uint8',    \n",
    "        'swimDistance'      : 'float16',    \n",
    "        'teamKills'         : 'uint8',    \n",
    "        'vehicleDestroys'   : 'uint8',    \n",
    "        'walkDistance'      : 'float16',    \n",
    "        'weaponsAcquired'   : 'uint8',    \n",
    "        'winPoints'         : 'uint8', \n",
    "        'winPlacePerc'      : 'float16' \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 타입을 pd.read_csv에서 설정\n",
    "data_dtypes = pd.read_csv('./data/train_V2.csv', dtype=dtypes)\n",
    "data_df = pd.read_csv('./data/train_V2.csv') # 파이썬이 알아서 데이터 타입 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtypes.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you do not want to do the above, it's a good idea to use kaggler's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    #start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    #end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = reduce_mem_usage(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Importing selected rows of the a file.(Sampling)\n",
    "If the size of the data is large as in this competition, you can try sampling. If you check code working well, use selected rows not all rows. ( it is called debug )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtypes = pd.read_csv('./data/train_V2.csv',nrows=10000 , dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomSampling이 되는지?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Importing just selected columns\n",
    "If you want to analyze just some specific feature, you can import just the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Id', 'groupId', 'matchId','killPlace','killPoints','kills','killStreaks','longestKill','winPlacePerc']\n",
    "\n",
    "dtypes = {\n",
    "        'Id'                : 'uint32',\n",
    "        'groupId'           : 'uint32',\n",
    "        'matchId'           : 'uint16',   \n",
    "        'killPlace'         : 'uint8',    \n",
    "        'killPoints'        : 'uint8',    \n",
    "        'kills'             : 'uint8',    \n",
    "        'killStreaks'       : 'uint8',    \n",
    "        'longestKill'       : 'float16',    \n",
    "        'winPlacePerc'      : 'float16' \n",
    "}\n",
    "example = pd.read_csv('./data/train_V2.csv', usecols=columns, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using debug mode\n",
    "Many people try to make feature engineering and predict pipelines. However, if the size of the data is large, it takes too long to create a variable or training a model. In this case, we can save time and effort by drawing a sample in advance as metioned above.<br>\n",
    "<br>\n",
    "로직이나 코드 테스트 할 때는 데이터를 많이 불러와서 실행할 필요 없으므로, 조금만 불러와서 로직 테스트하자!!!<br>\n",
    "내가 코드 로직 확인할 때는 debug=False로 실행<br>\n",
    "모델 테스트 할때는 debug=True로 써놓고 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True\n",
    "if debug:\n",
    "    df_train = pd.read_csv('./data/train_V2.csv',nrows=10000 , dtype=dtypes)\n",
    "    df_test  = pd.read_csv('./data/train_V2.csv', dtype=dtypes)\n",
    "else:\n",
    "    df_train = pd.read_csv('./data/train_V2.csv', dtype=dtypes)\n",
    "    df_test  = pd.read_csv('./data/train_V2.csv', dtype=dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lightgbm: prevent RAM spike (explode) at the init training\n",
    "의사결정 트리에서 가장 좋은 성능을 내는 모델<br>\n",
    "아직 잘 모르겠음...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Faster Training\n",
    "### https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/56158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm: prevent RAM spike (explode) at the init training\n",
    "### https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
