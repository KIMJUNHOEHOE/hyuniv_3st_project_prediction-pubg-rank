{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 삭제없이 multi linear regression\n",
    "> - min_max_scaler 를 사용해서 변수 normal 화\n",
    "> - matchtype one-hot-encoding으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook\n",
    "import sklearn.preprocessing as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/train_V2.csv')\n",
    "train_df, test_df = train_test_split(data, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀분석을 하기 위해 문자열을 범주값으로 변환\n",
    "matchTyp = {'squad-fpp': 0, 'duo': 1, 'solo-fpp': 2, 'squad': 3, 'duo-fpp': 4, 'solo': 5,\n",
    "       'normal-squad-fpp': 6, 'crashfpp': 7, 'flaretpp': 8, 'normal-solo-fpp': 9,\n",
    "       'flarefpp': 10, 'normal-duo-fpp': 11, 'normal-duo': 12, 'normal-squad': 13,\n",
    "       'crashtpp': 14, 'normal-solo': 15 }\n",
    "\n",
    "train_df['matchType'] = train_df['matchType'].replace(matchTyp)\n",
    "test_df['matchType'] = test_df['matchType'].replace(matchTyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# null값 확인 및 \n",
    "# inplace=False로 하면 기존 혹은 새로운 변수에 할당해야 하고, inplace = True 하면 해당변수에 적용됨\n",
    "# na가 포함된 행을 제거하는 것은 데이터 소실이 크기 때문에 inplace=False가 default\n",
    "train_df.dropna(inplace = True)\n",
    "print(train_df.isnull().any().any())\n",
    "test_df.dropna(inplace = True)\n",
    "print(test_df.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop함수와 dropna 함수는 데이터 소실 우려가 있기 때문에 할당하거나, inplace=True 매개변수를 가져야 정정되도록 default설정\n",
    "noId_train_df = train_df.drop(['Id','groupId','matchId'], axis = 1)\n",
    "noId_test_df = test_df.drop(['Id','groupId','matchId'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_df['matchType']의 결과는 [[0,1,2,3,4,5]] 값인데, 우리가 원하는건 [[0],[1],[2],[3]]\n",
    "# matchType_array = np.array(noId_train_df['matchType']).reshape(len(noId_train_df['matchType']),1) # reshape 1차원을 원하는 shape로 변경\n",
    "\n",
    "# # onehotencoding으로 변환\n",
    "# ohe = sk.OneHotEncoder()\n",
    "# ohe.fit(matchType_array)\n",
    "# matchType_one_hot = ohe.transform(matchType_array).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matchType_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3112876"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[:,matchType_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:,matchType_index].resize(len(noId_train_df['matchType']),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4., 0., ..., 4., 5., 7.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:,matchType_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b81ea37b3ecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatchType_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatchType_one_hot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatchType_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatchType_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatchType_one_hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_train[:,matchType_index])):\n",
    "    print(type(matchType_one_hot[i]))\n",
    "    print(type(x_train[:,matchType_index][i]))\n",
    "    x_train[:,matchType_index] = matchType_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.08695652 0.         ... 0.07090768 0.02118644 0.75524476]\n",
      " [0.04761905 0.         0.02549879 ... 0.10201707 0.02118644 0.        ]\n",
      " [0.         0.         0.01490478 ... 0.01437936 0.01271186 0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.01255593 ... 0.00224438 0.00423729 0.        ]\n",
      " [0.         0.         0.         ... 0.07183863 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "train_np = np.array(noId_train_df)\n",
    "test_np = np.array(noId_test_df)\n",
    "\n",
    "# matchtype은 12번째 index\n",
    "matchType_index = list(noId_train_df.columns).index('matchType')\n",
    "nb_classes = 16  # 0 ~ 15 개의 matchType 범주\n",
    "\n",
    "x_train = train_np[:,0:-1]  # id, groupId, matchid 제외\n",
    "\n",
    "x_train[:,0:matchType_index] = MinMaxScaler(x_train)[:,0:matchType_index] # matchtype 제외시키기 위해\n",
    "x_train[:,matchType_index+1:] = MinMaxScaler(x_train)[:,matchType_index+1:] # matchtype 제외시키기 위해\n",
    "y_train = train_np[:, [-1]]\n",
    "\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "train_np = np.array(noId_train_df)\n",
    "test_np = np.array(noId_test_df)\n",
    "\n",
    "# matchtype은 12번째 값\n",
    "# matchType은 0 아니면 1 범주값으로 MinMaxScaler 적용할 필요 없음\n",
    "matchType_index = list(noId_train_df.columns).index('matchType')\n",
    "\n",
    "x_train = train_np[:,0:-1]  # id, groupId, matchid 제외\n",
    "x_train[:,0:matchType_index] = MinMaxScaler(x_train)[:,0:matchType_index] # matchtype 제외시키기 위해\n",
    "x_train[:,matchType_index+1:] = MinMaxScaler(x_train)[:,matchType_index+1:] # matchtype 제외시키기 위해\n",
    "y_train = train_np[:, [-1]]\n",
    "print('pass')\n",
    "\n",
    "x_test = test_np[:,:-1] # id, groupId, matchid 제외\n",
    "x_test[:,0:16] = MinMaxScaler(x_test)[:,0:16] # matchtype 제외시키기 위해\n",
    "x_test[:,17:] = MinMaxScaler(x_test)[:,17:] # matchtype 제외시키기 위해\n",
    "y_test = test_np[:,[-1]]\n",
    "print('pass')\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 25]) # 총 29개 칼럼에서 3개 빼면 26, y값 까지 빼면 25\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([25, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis(model)\n",
    "# one-hot-encoding 한 'matchType' 을 행으로 더함\n",
    "# x변수는 [1,2,3, [0,1,0,0], 4] 와 같은 형태이므로\n",
    "hypothesis = tf.reduce_sum(tf.matmul(X, W), axis=1) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(5001)):\n",
    "        cost_val, hy_val, _ = sess.run(\n",
    "            [cost, hypothesis, train], feed_dict={X: x_train, Y: y_train})\n",
    "        if step % 100 == 0:\n",
    "            print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "    Weight = sess.run(W)\n",
    "    print(\"W\\t\" , Weight)\n",
    "    y_predict = sess.run(hypothesis, feed_dict={X:x_test})\n",
    "    print(\"Predict\\t\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = pd.DataFrame(test_df['Id'])\n",
    "test_winPlacePerc = pd.DataFrame(test_df['winPlacePerc'])\n",
    "y_predict_df = pd.DataFrame(y_predict,index = test_id.index, columns=['predict'])\n",
    "diff = pd.DataFrame(test_df['winPlacePerc']-y_predict_df['predict'],\n",
    "                   columns=['diff'])\n",
    "\n",
    "mae = sum(abs(diff['diff']))/diff['diff'].count() # Mean absolute error\n",
    "\n",
    "result = pd.DataFrame({'Id':test_id['Id'],'winPlacePerc':test_winPlacePerc['winPlacePerc'], \n",
    "                       'predict':y_predict_df['predict'],'diff':diff['diff'],'MAE':mae})\n",
    "result.to_csv('./result/Multi_Linear_Regression_all_inputs_with_matchType(one-hot-encoding)_minmaxscaler.csv',sep=',', encoding='utf-8')\n",
    "print(result.head())\n",
    "print('Mae\\t : ', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
