{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe display 옵션\n",
    "pd.set_option('display.max_columns' , 60)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./data/final3/final3_Data(version3).csv', dtype={                  \n",
    "\t\t\t\t\t'matchType'                         : 'int16',\n",
    "            'DBNOs_max'                         : 'float32',\n",
    "            'assists_max'                       : 'float32',\n",
    "            'boosts_max'                        : 'float32',\n",
    "            'damageDealt_max'                   : 'float32',\n",
    "            'headshotKills_max'                 : 'float32',\n",
    "            'heals_max'                         : 'float32',\n",
    "            'killStreaks_max'                   : 'float32',\n",
    "            'kills_max'                         : 'float32',\n",
    "            'longestKill_max'                   : 'float32',\n",
    "            'revives_max'                       : 'float32',\n",
    "            'roadKills_max'                     : 'float32',\n",
    "            'teamKills_max'                     : 'float32',\n",
    "            'vehicleDestroys_max'               : 'float32',\n",
    "            'weaponsAcquired_max'               : 'float32',\n",
    "            'DBNOs_min'                         : 'float32',\n",
    "            'assists_min'                       : 'float32',\n",
    "            'boosts_min'                        : 'float32',\n",
    "            'damageDealt_min'                   : 'float32',\n",
    "            'headshotKills_min'                 : 'float32',\n",
    "            'heals_min'                         : 'float32',\n",
    "            'killStreaks_min'                   : 'float32',\n",
    "            'kills_min'                         : 'float32',\n",
    "            'longestKill_min'                   : 'float32',\n",
    "            'revives_min'                       : 'float32',\n",
    "            'roadKills_min'                     : 'float32',\n",
    "            'teamKills_min'                     : 'float32',\n",
    "            'vehicleDestroys_min'               : 'float32',\n",
    "            'weaponsAcquired_min'               : 'float32',\n",
    "            'assists_mean'                      : 'float32',\n",
    "            'boosts_mean'                       : 'float32',\n",
    "            'damageDealt_mean'                  : 'float32',\n",
    "            'DBNOs_mean'                        : 'float32',\n",
    "            'headshotKills_mean'                : 'float32',\n",
    "            'heals_mean'                        : 'float32',\n",
    "            'kills_mean'                        : 'float32',\n",
    "            'killStreaks_mean'                  : 'float32',\n",
    "            'longestKill_mean'                  : 'float32',\n",
    "            'revives_mean'                      : 'float32',\n",
    "            'roadKills_mean'                    : 'float32',\n",
    "            'teamKills_mean'                    : 'float32',\n",
    "            'vehicleDestroys_mean'              : 'float32',\n",
    "            'weaponsAcquired_mean'              : 'float32',\n",
    "            'assists_match_mean'                : 'float32',\n",
    "            'boosts_match_mean'                 : 'float32',\n",
    "            'damageDealt_match_mean'            : 'float32',\n",
    "            'DBNOs_match_mean'                  : 'float32',\n",
    "            'headshotKills_match_mean'          : 'float32',\n",
    "            'heals_match_mean'                  : 'float32',\n",
    "            'kills_match_mean'                  : 'float32',\n",
    "            'killStreaks_match_mean'            : 'float32',\n",
    "            'longestKill_match_mean'            : 'float32',\n",
    "            'revives_match_mean'                : 'float32',\n",
    "            'roadKills_match_mean'              : 'float32',\n",
    "            'teamKills_match_mean'              : 'float32',\n",
    "            'vehicleDestroys_match_mean'        : 'float32',\n",
    "            'weaponsAcquired_match_mean'        : 'float32',\n",
    "            'match_size'                        : 'int16',\n",
    "            'total_distance_max'                : 'float32',\n",
    "            'total_distance_min'                : 'float32',\n",
    "            'total_distance_mean'               : 'float32',\n",
    "            'total_distance_match_mean'         : 'float32',\n",
    "            'winPlacePerc'                      : 'float32'\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_set():\n",
    "    solo_data = raw_data[raw_data['matchType'] == 1]\n",
    "    solo_data = solo_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(solo_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "    solo_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    solo_regr.fit(train_x, train_y)\n",
    "    print(\"Rnadom Forest\")\n",
    "    print('mae train: ', mean_absolute_error(solo_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(solo_regr.predict(test_x), test_y))\n",
    "    return solo_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(473925, 57) (203111, 57) (473925,) (203111,)\n",
      "Rnadom Forest\n",
      "mae train:  0.029941599515396128\n",
      "mae test:  0.06705750957697847\n"
     ]
    }
   ],
   "source": [
    "solo_regr = solo_set() # max depth = 100, max_features = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duo_set():\n",
    "    duo_data = raw_data[raw_data['matchType'] == 2]\n",
    "#     print(duo_data.columns)\n",
    "    duo_data = duo_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(duo_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    duo_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    duo_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(duo_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(duo_regr.predict(test_x), test_y))\n",
    "    return duo_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(897619, 57) (384694, 57) (897619,) (384694,)\n",
      "Random Forest\n",
      "mae train:  0.01667576741763037\n",
      "mae test:  0.038486791540625884\n"
     ]
    }
   ],
   "source": [
    "duo_regr = duo_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_set():\n",
    "    squad_data = raw_data[raw_data['matchType'] == 3]\n",
    "#     print(squad_data.columns)\n",
    "    squad_data = squad_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(squad_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    squad_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    squad_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(squad_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(squad_regr.predict(test_x), test_y))\n",
    "    return squad_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(1636128, 57) (701198, 57) (1636128,) (701198,)\n",
      "Rnadom Forest\n",
      "mae train:  0.009541027111324011\n",
      "mae test:  0.02142940802265562\n"
     ]
    }
   ],
   "source": [
    "squad_regr = squad_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_set():\n",
    "    other_data = raw_data[raw_data['matchType'] == 4]\n",
    "#     print(other_data.columns)\n",
    "    other_data = other_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(other_data, train_size = 0.7)\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    other_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    other_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(other_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(other_regr.predict(test_x), test_y))\n",
    "    return other_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18695, 57) (8013, 57) (18695,) (8013,)\n",
      "False\n",
      "False\n",
      "Random Forest\n",
      "mae train:  0.023979650981535594\n",
      "mae test:  0.0524897812048827\n"
     ]
    }
   ],
   "source": [
    "other_regr = other_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Initializing from file failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-6b146f879063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtestSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/test_V2(제출용).csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtestSet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'groupId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'matchId'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'damageDealt_mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'damageDealt_max'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'damageDealt_min'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'damageDealt_match_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtestSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Initializing from file failed"
     ]
    }
   ],
   "source": [
    "testSet = pd.read_csv('./data/final3/final3_Data_test(version3).csv')\n",
    "testSet = testSet.drop(columns=['groupId', 'matchId','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'])\n",
    "testSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet['winPlacePerc'] = 0.0\n",
    "_cols = ['DBNOs_max', 'assists_max', 'boosts_max',\n",
    "       'headshotKills_max', 'heals_max', 'killStreaks_max', 'kills_max',\n",
    "       'longestKill_max', 'revives_max', 'roadKills_max', 'teamKills_max',\n",
    "       'vehicleDestroys_max', 'weaponsAcquired_max', 'DBNOs_min',\n",
    "       'assists_min', 'boosts_min', 'headshotKills_min', 'heals_min',\n",
    "       'killStreaks_min', 'kills_min', 'longestKill_min', 'revives_min',\n",
    "       'roadKills_min', 'teamKills_min', 'vehicleDestroys_min',\n",
    "       'weaponsAcquired_min', 'assists_mean', 'boosts_mean', 'DBNOs_mean',\n",
    "       'headshotKills_mean', 'heals_mean', 'kills_mean', 'killStreaks_mean',\n",
    "       'longestKill_mean', 'revives_mean', 'roadKills_mean', 'teamKills_mean',\n",
    "       'vehicleDestroys_mean', 'weaponsAcquired_mean', 'assists_match_mean',\n",
    "       'boosts_match_mean', 'DBNOs_match_mean', 'headshotKills_match_mean',\n",
    "       'heals_match_mean', 'kills_match_mean', 'killStreaks_match_mean',\n",
    "       'longestKill_match_mean', 'revives_match_mean', 'roadKills_match_mean',\n",
    "       'teamKills_match_mean', 'vehicleDestroys_match_mean',\n",
    "       'weaponsAcquired_match_mean', 'match_size', 'total_distance_max',\n",
    "       'total_distance_min', 'total_distance_mean',\n",
    "       'total_distance_match_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for idx in range(len(testSet)):\n",
    "    if testSet.loc[idx,'matchType'] == 1:\n",
    "        _temp = solo_regr.predict(np.array(testSet.loc[idx,solo_cols]).reshape(1,-1))\n",
    "    elif testSet.loc[idx, 'matchType'] == 2:\n",
    "        _temp = duo_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    elif testSet.loc[idx, 'matchType'] == 3:\n",
    "        _temp = squad_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    else:\n",
    "        _temp = other_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    testSet.loc[idx,'winPlacePerc'] = _temp\n",
    "testSet.head(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testSet[testSet['matchType'] == 1].loc[:,'winPlacePerc'] = solo_regr.predict(testSet[testSet['matchType']==1].loc[:,solo_cols])\n",
    "#testSet[testSet['matchType'] == 2].loc[:,'winPlacePerc'] = duo_regr.predict(testSet[testSet['matchType']==2].loc[:,others_cols])\n",
    "#testSet[testSet['matchType'] == 3].loc[:,'winPlacePerc'] = squad_regr.predict(testSet[testSet['matchType']==3].loc[:,others_cols])\n",
    "#testSet[testSet['matchType'] == 4].loc[:,'winPlacePerc'] = other_regr.predict(testSet[testSet['matchType']==4].loc[:,others_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 1].loc[:,'Id'],\n",
    "    'winPlacePerc': solo_regr.predict(testSet[testSet['matchType']==1].loc[:,_cols])\n",
    "})\n",
    "\n",
    "duo_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 2].loc[:,'Id'],\n",
    "    'winPlacePerc': duo_regr.predict(testSet[testSet['matchType']==2].loc[:,_cols])\n",
    "})\n",
    "\n",
    "squad_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 3].loc[:,'Id'],\n",
    "    'winPlacePerc': squad_regr.predict(testSet[testSet['matchType']==3].loc[:,_cols])\n",
    "})\n",
    "\n",
    "others_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 4].loc[:,'Id'],\n",
    "    'winPlacePerc': other_regr.predict(testSet[testSet['matchType']==4].loc[:,_cols])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_result = pd.concat([solo_result, duo_result, squad_result, others_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, winPlacePerc]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result[subm_result['winPlacePerc']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, winPlacePerc]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result[subm_result['winPlacePerc']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>315c96c26c9aac</td>\n",
       "      <td>0.210333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>311b84c6ff4390</td>\n",
       "      <td>0.630954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b7807186e3f679</td>\n",
       "      <td>0.831593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>92022479b92ce7</td>\n",
       "      <td>0.901058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>47143f942503e0</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  winPlacePerc\n",
       "4   315c96c26c9aac      0.210333\n",
       "7   311b84c6ff4390      0.630954\n",
       "13  b7807186e3f679      0.831593\n",
       "17  92022479b92ce7      0.901058\n",
       "35  47143f942503e0      0.339666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4323383\n",
      "4323383\n"
     ]
    }
   ],
   "source": [
    "print(len(subm_result['Id']))\n",
    "print(len(subm_result['winPlacePerc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_result.to_csv('./data/result/final3(version3).csv',sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "solo_file = '../model/random_forest_final4_solo_100_3_05.sav'\n",
    "pickle.dump(solo_regr, open(solo_file, 'wb'))\n",
    "\n",
    "duo_file = '../model/random_forest_final4_duo_100_3_05.sav'\n",
    "pickle.dump(duo_regr, open(duo_file, 'wb'))\n",
    "\n",
    "squad_file = '../model/random_forest_final4_squad_100_3_05.sav'\n",
    "pickle.dump(squad_regr, open(squad_file, 'wb'))\n",
    "\n",
    "other_file = '../model/random_forest_final4_other_100_3_05.sav'\n",
    "pickle.dump(other_regr, open(other_file, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(solo_file, 'rb'))\n",
    "#result = loaded_model.predict(X_test, Y_test)\n",
    "#print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
