{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JunHweKim\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe display 옵션\n",
    "pd.set_option('display.max_columns' , 60)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./data/final3/final3_Data(version3).csv', dtype={                  \n",
    "\t\t\t\t\t'matchType'                         : 'int16',\n",
    "            'DBNOs_max'                         : 'float32',\n",
    "            'assists_max'                       : 'float32',\n",
    "            'boosts_max'                        : 'float32',\n",
    "            'damageDealt_max'                   : 'float32',\n",
    "            'headshotKills_max'                 : 'float32',\n",
    "            'heals_max'                         : 'float32',\n",
    "            'killStreaks_max'                   : 'float32',\n",
    "            'kills_max'                         : 'float32',\n",
    "            'longestKill_max'                   : 'float32',\n",
    "            'revives_max'                       : 'float32',\n",
    "            'roadKills_max'                     : 'float32',\n",
    "            'teamKills_max'                     : 'float32',\n",
    "            'vehicleDestroys_max'               : 'float32',\n",
    "            'weaponsAcquired_max'               : 'float32',\n",
    "            'DBNOs_min'                         : 'float32',\n",
    "            'assists_min'                       : 'float32',\n",
    "            'boosts_min'                        : 'float32',\n",
    "            'damageDealt_min'                   : 'float32',\n",
    "            'headshotKills_min'                 : 'float32',\n",
    "            'heals_min'                         : 'float32',\n",
    "            'killStreaks_min'                   : 'float32',\n",
    "            'kills_min'                         : 'float32',\n",
    "            'longestKill_min'                   : 'float32',\n",
    "            'revives_min'                       : 'float32',\n",
    "            'roadKills_min'                     : 'float32',\n",
    "            'teamKills_min'                     : 'float32',\n",
    "            'vehicleDestroys_min'               : 'float32',\n",
    "            'weaponsAcquired_min'               : 'float32',\n",
    "            'assists_mean'                      : 'float32',\n",
    "            'boosts_mean'                       : 'float32',\n",
    "            'damageDealt_mean'                  : 'float32',\n",
    "            'DBNOs_mean'                        : 'float32',\n",
    "            'headshotKills_mean'                : 'float32',\n",
    "            'heals_mean'                        : 'float32',\n",
    "            'kills_mean'                        : 'float32',\n",
    "            'killStreaks_mean'                  : 'float32',\n",
    "            'longestKill_mean'                  : 'float32',\n",
    "            'revives_mean'                      : 'float32',\n",
    "            'roadKills_mean'                    : 'float32',\n",
    "            'teamKills_mean'                    : 'float32',\n",
    "            'vehicleDestroys_mean'              : 'float32',\n",
    "            'weaponsAcquired_mean'              : 'float32',\n",
    "            'assists_match_mean'                : 'float32',\n",
    "            'boosts_match_mean'                 : 'float32',\n",
    "            'damageDealt_match_mean'            : 'float32',\n",
    "            'DBNOs_match_mean'                  : 'float32',\n",
    "            'headshotKills_match_mean'          : 'float32',\n",
    "            'heals_match_mean'                  : 'float32',\n",
    "            'kills_match_mean'                  : 'float32',\n",
    "            'killStreaks_match_mean'            : 'float32',\n",
    "            'longestKill_match_mean'            : 'float32',\n",
    "            'revives_match_mean'                : 'float32',\n",
    "            'roadKills_match_mean'              : 'float32',\n",
    "            'teamKills_match_mean'              : 'float32',\n",
    "            'vehicleDestroys_match_mean'        : 'float32',\n",
    "            'weaponsAcquired_match_mean'        : 'float32',\n",
    "            'match_size'                        : 'int16',\n",
    "            'total_distance_max'                : 'float32',\n",
    "            'total_distance_min'                : 'float32',\n",
    "            'total_distance_mean'               : 'float32',\n",
    "            'total_distance_match_mean'         : 'float32',\n",
    "            'winPlacePerc'                      : 'float32'\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solo_set():\n",
    "    solo_data = raw_data[raw_data['matchType'] == 1]\n",
    "    solo_data = solo_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(solo_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "    solo_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    solo_regr.fit(train_x, train_y)\n",
    "    print(\"Rnadom Forest\")\n",
    "    print('mae train: ', mean_absolute_error(solo_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(solo_regr.predict(test_x), test_y))\n",
    "    return solo_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(473925, 57) (203111, 57) (473925,) (203111,)\n",
      "Rnadom Forest\n",
      "mae train:  0.0298902602745969\n",
      "mae test:  0.06730540313977572\n"
     ]
    }
   ],
   "source": [
    "solo_regr = solo_set() # max depth = 100, max_features = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duo_set():\n",
    "    duo_data = raw_data[raw_data['matchType'] == 2]\n",
    "#     print(duo_data.columns)\n",
    "    duo_data = duo_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(duo_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    duo_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    duo_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(duo_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(duo_regr.predict(test_x), test_y))\n",
    "    return duo_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(897619, 57) (384694, 57) (897619,) (384694,)\n",
      "Random Forest\n",
      "mae train:  0.016686715347369162\n",
      "mae test:  0.038432908507254455\n"
     ]
    }
   ],
   "source": [
    "duo_regr = duo_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_set():\n",
    "    squad_data = raw_data[raw_data['matchType'] == 3]\n",
    "#     print(squad_data.columns)\n",
    "    squad_data = squad_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(squad_data, train_size = 0.7)\n",
    "\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "\n",
    "\n",
    "    squad_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    squad_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(squad_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(squad_regr.predict(test_x), test_y))\n",
    "    return squad_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "(1636128, 57) (701198, 57) (1636128,) (701198,)\n",
      "Random Forest\n",
      "mae train:  0.009552013637234073\n",
      "mae test:  0.021366521872551853\n"
     ]
    }
   ],
   "source": [
    "squad_regr = squad_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_set():\n",
    "    other_data = raw_data[raw_data['matchType'] == 4]\n",
    "#     print(other_data.columns)\n",
    "    other_data = other_data.drop(columns=['Id', 'groupId', 'matchId','matchType','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'], axis=1)\n",
    "    train_df, test_df = train_test_split(other_data, train_size = 0.7)\n",
    "    train_y = np.array(train_df['winPlacePerc'])\n",
    "    train_x = train_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "\n",
    "    test_y = np.array(test_df['winPlacePerc'])\n",
    "    test_x = test_df.drop(columns=['winPlacePerc'], axis=1)\n",
    "    print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)\n",
    "    train_df.dropna(inplace = True)\n",
    "    print(train_df.isnull().any().any())\n",
    "    test_df.dropna(inplace = True)\n",
    "    print(test_df.isnull().any().any())\n",
    "\n",
    "    other_regr = RandomForestRegressor(n_estimators=100, min_samples_leaf=2, max_features=0.5, n_jobs=-1, max_depth=100)\n",
    "    other_regr.fit(train_x, train_y)\n",
    "    print(\"Random Forest\")\n",
    "    print('mae train: ', mean_absolute_error(other_regr.predict(train_x), train_y))\n",
    "    print('mae test: ', mean_absolute_error(other_regr.predict(test_x), test_y))\n",
    "    return other_regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18695, 57) (8013, 57) (18695,) (8013,)\n",
      "False\n",
      "False\n",
      "Random Forest\n",
      "mae train:  0.02362954740499967\n",
      "mae test:  0.05416925182347299\n"
     ]
    }
   ],
   "source": [
    "other_regr = other_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'matchType', 'DBNOs_max', 'assists_max', 'boosts_max',\n",
       "       'headshotKills_max', 'heals_max', 'killStreaks_max', 'kills_max',\n",
       "       'longestKill_max', 'revives_max', 'roadKills_max', 'teamKills_max',\n",
       "       'vehicleDestroys_max', 'weaponsAcquired_max', 'DBNOs_min',\n",
       "       'assists_min', 'boosts_min', 'headshotKills_min', 'heals_min',\n",
       "       'killStreaks_min', 'kills_min', 'longestKill_min', 'revives_min',\n",
       "       'roadKills_min', 'teamKills_min', 'vehicleDestroys_min',\n",
       "       'weaponsAcquired_min', 'assists_mean', 'boosts_mean', 'DBNOs_mean',\n",
       "       'headshotKills_mean', 'heals_mean', 'kills_mean', 'killStreaks_mean',\n",
       "       'longestKill_mean', 'revives_mean', 'roadKills_mean', 'teamKills_mean',\n",
       "       'vehicleDestroys_mean', 'weaponsAcquired_mean', 'assists_match_mean',\n",
       "       'boosts_match_mean', 'DBNOs_match_mean', 'headshotKills_match_mean',\n",
       "       'heals_match_mean', 'kills_match_mean', 'killStreaks_match_mean',\n",
       "       'longestKill_match_mean', 'revives_match_mean', 'roadKills_match_mean',\n",
       "       'teamKills_match_mean', 'vehicleDestroys_match_mean',\n",
       "       'weaponsAcquired_match_mean', 'match_size', 'total_distance_max',\n",
       "       'total_distance_min', 'total_distance_mean',\n",
       "       'total_distance_match_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet = pd.read_csv('./data/final3/final3_Data_test(version3).csv')\n",
    "testSet = testSet.drop(columns=['groupId', 'matchId','damageDealt_mean','damageDealt_max','damageDealt_min','damageDealt_match_mean'])\n",
    "testSet.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet['winPlacePerc'] = 0.0\n",
    "_cols = ['DBNOs_max', 'assists_max', 'boosts_max',\n",
    "       'headshotKills_max', 'heals_max', 'killStreaks_max', 'kills_max',\n",
    "       'longestKill_max', 'revives_max', 'roadKills_max', 'teamKills_max',\n",
    "       'vehicleDestroys_max', 'weaponsAcquired_max', 'DBNOs_min',\n",
    "       'assists_min', 'boosts_min', 'headshotKills_min', 'heals_min',\n",
    "       'killStreaks_min', 'kills_min', 'longestKill_min', 'revives_min',\n",
    "       'roadKills_min', 'teamKills_min', 'vehicleDestroys_min',\n",
    "       'weaponsAcquired_min', 'assists_mean', 'boosts_mean', 'DBNOs_mean',\n",
    "       'headshotKills_mean', 'heals_mean', 'kills_mean', 'killStreaks_mean',\n",
    "       'longestKill_mean', 'revives_mean', 'roadKills_mean', 'teamKills_mean',\n",
    "       'vehicleDestroys_mean', 'weaponsAcquired_mean', 'assists_match_mean',\n",
    "       'boosts_match_mean', 'DBNOs_match_mean', 'headshotKills_match_mean',\n",
    "       'heals_match_mean', 'kills_match_mean', 'killStreaks_match_mean',\n",
    "       'longestKill_match_mean', 'revives_match_mean', 'roadKills_match_mean',\n",
    "       'teamKills_match_mean', 'vehicleDestroys_match_mean',\n",
    "       'weaponsAcquired_match_mean', 'match_size', 'total_distance_max',\n",
    "       'total_distance_min', 'total_distance_mean',\n",
    "       'total_distance_match_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for idx in range(len(testSet)):\n",
    "    if testSet.loc[idx,'matchType'] == 1:\n",
    "        _temp = solo_regr.predict(np.array(testSet.loc[idx,solo_cols]).reshape(1,-1))\n",
    "    elif testSet.loc[idx, 'matchType'] == 2:\n",
    "        _temp = duo_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    elif testSet.loc[idx, 'matchType'] == 3:\n",
    "        _temp = squad_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    else:\n",
    "        _temp = other_regr.predict(np.array(testSet.loc[idx,others_cols]).reshape(1,-1))\n",
    "    testSet.loc[idx,'winPlacePerc'] = _temp\n",
    "testSet.head(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testSet[testSet['matchType'] == 1].loc[:,'winPlacePerc'] = solo_regr.predict(testSet[testSet['matchType']==1].loc[:,solo_cols])\n",
    "#testSet[testSet['matchType'] == 2].loc[:,'winPlacePerc'] = duo_regr.predict(testSet[testSet['matchType']==2].loc[:,others_cols])\n",
    "#testSet[testSet['matchType'] == 3].loc[:,'winPlacePerc'] = squad_regr.predict(testSet[testSet['matchType']==3].loc[:,others_cols])\n",
    "#testSet[testSet['matchType'] == 4].loc[:,'winPlacePerc'] = other_regr.predict(testSet[testSet['matchType']==4].loc[:,others_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 1].loc[:,'Id'],\n",
    "    'winPlacePerc': solo_regr.predict(testSet[testSet['matchType']==1].loc[:,_cols])\n",
    "})\n",
    "\n",
    "duo_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 2].loc[:,'Id'],\n",
    "    'winPlacePerc': duo_regr.predict(testSet[testSet['matchType']==2].loc[:,_cols])\n",
    "})\n",
    "\n",
    "squad_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 3].loc[:,'Id'],\n",
    "    'winPlacePerc': squad_regr.predict(testSet[testSet['matchType']==3].loc[:,_cols])\n",
    "})\n",
    "\n",
    "others_result = pd.DataFrame({\n",
    "    'Id': testSet[testSet['matchType'] == 4].loc[:,'Id'],\n",
    "    'winPlacePerc': other_regr.predict(testSet[testSet['matchType']==4].loc[:,_cols])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_result = pd.concat([solo_result, duo_result, squad_result, others_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, winPlacePerc]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result[subm_result['winPlacePerc']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, winPlacePerc]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result[subm_result['winPlacePerc']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>winPlacePerc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>315c96c26c9aac</td>\n",
       "      <td>0.210333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>311b84c6ff4390</td>\n",
       "      <td>0.630954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b7807186e3f679</td>\n",
       "      <td>0.831593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>92022479b92ce7</td>\n",
       "      <td>0.901058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>47143f942503e0</td>\n",
       "      <td>0.339666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id  winPlacePerc\n",
       "4   315c96c26c9aac      0.210333\n",
       "7   311b84c6ff4390      0.630954\n",
       "13  b7807186e3f679      0.831593\n",
       "17  92022479b92ce7      0.901058\n",
       "35  47143f942503e0      0.339666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934174\n",
      "1934174\n"
     ]
    }
   ],
   "source": [
    "print(len(subm_result['Id']))\n",
    "print(len(subm_result['winPlacePerc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_result.to_csv('./data/result/final3(version3).csv',sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "solo_file = '../model/random_forest_final4_solo_100_3_05.sav'\n",
    "pickle.dump(solo_regr, open(solo_file, 'wb'))\n",
    "\n",
    "duo_file = '../model/random_forest_final4_duo_100_3_05.sav'\n",
    "pickle.dump(duo_regr, open(duo_file, 'wb'))\n",
    "\n",
    "squad_file = '../model/random_forest_final4_squad_100_3_05.sav'\n",
    "pickle.dump(squad_regr, open(squad_file, 'wb'))\n",
    "\n",
    "other_file = '../model/random_forest_final4_other_100_3_05.sav'\n",
    "pickle.dump(other_regr, open(other_file, 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "#loaded_model = pickle.load(open(solo_file, 'rb'))\n",
    "#result = loaded_model.predict(X_test, Y_test)\n",
    "#print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
